#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—ñ–≤ –¥–ª—è –≤—Å—ñ—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤.
–ü—ñ–¥—Ç—Ä–∏–º—É—î —Ç–∏–ø–∏: dealer, retail

–û–ù–û–í–õ–ï–ù–û: –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–æ–≤–∞—Ä—ñ–≤ –ø–æ –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É (–∞—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞)
"""

import csv
import os
import sys
from typing import Dict, List, Set


SUPPLIERS = ['viatec', 'secur', 'neolight', 'lun', 'eserver']
TYPES = ['dealer', 'retail']


def detect_encoding(file_path: str) -> str:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î –∫–æ–¥—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É."""
    # –°–ø—Ä–æ–±—É—î–º–æ —Å–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ –ø–µ—Ä—à—ñ –±–∞–π—Ç–∏ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è
    try:
        with open(file_path, 'rb') as f:
            raw_data = f.read(10000)  # –ü–µ—Ä—à—ñ 10KB
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ BOM UTF-8
        if raw_data.startswith(b'\xef\xbb\xbf'):
            return 'utf-8-sig'
        
        # –°–ø—Ä–æ–±—É—î–º–æ —Ä—ñ–∑–Ω—ñ –∫–æ–¥—É–≤–∞–Ω–Ω—è
        encodings_to_try = [
            'utf-8',
            'utf-8-sig', 
            'windows-1251',
            'cp1251',
            'latin-1'
        ]
        
        for encoding in encodings_to_try:
            try:
                raw_data.decode(encoding)
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∑ –∫–∏—Ä–∏–ª–∏—Ü–µ—é
                try:
                    text = raw_data.decode(encoding)
                    if '–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó' in text or '–ö–æ–¥_—Ç–æ–≤–∞—Ä—É' in text:
                        return encoding
                except:
                    pass
                # –Ø–∫—â–æ –¥–µ–∫–æ–¥—É–≤–∞–Ω–Ω—è –ø—Ä–æ–π—à–ª–æ –±–µ–∑ –ø–æ–º–∏–ª–æ–∫, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ü–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è
                return encoding
            except (UnicodeDecodeError, LookupError):
                continue
                
    except Exception as e:
        print(f"‚ö†Ô∏è  –ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ–¥—É–≤–∞–Ω–Ω—è: {e}")
    
    # Fallback
    return 'utf-8-sig'


def read_csv_as_rows(file_path: str) -> tuple[List[List[str]], List[str]]:
    """–ß–∏—Ç–∞—î CSV —è–∫ —Å–ø–∏—Å–æ–∫ —Ä—è–¥–∫—ñ–≤ –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è–º –∫–æ–¥—É–≤–∞–Ω–Ω—è."""
    rows = []
    headers = []
    
    try:
        encoding = detect_encoding(file_path)
        print(f"üîç –ö–æ–¥—É–≤–∞–Ω–Ω—è: {encoding}")
        
        with open(file_path, 'r', encoding=encoding, errors='replace') as f:
            reader = csv.reader(f, delimiter=';')
            headers = next(reader)
            
            # –í–∏–≤–æ–¥–∏–º–æ –ø–µ—Ä—à—ñ 3 –∫–æ–ª–æ–Ω–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            print(f"üìã –ó–∞–≥–æ–ª–æ–≤–∫–∏: {headers[:3]}...")
            
            for row in reader:
                rows.append(row)
        
        print(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(rows)} —Ç–æ–≤–∞—Ä—ñ–≤ –∑ {os.path.basename(file_path)}")
        return rows, headers
        
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {file_path}")
        return [], []
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è: {e}")
        import traceback
        traceback.print_exc()
        return [], []


def get_field_index(headers: List[str], field_name: str) -> int:
    """–ü–æ–≤–µ—Ä—Ç–∞—î —ñ–Ω–¥–µ–∫—Å –ø–æ–ª—è –∞–±–æ -1."""
    try:
        return headers.index(field_name)
    except ValueError:
        print(f"‚ö†Ô∏è  –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–∫—É '{field_name}'")
        print(f"‚ö†Ô∏è  –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {headers[:10]}...")
        return -1


def get_max_product_code(rows: List[List[str]], code_idx: int) -> int:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π –∫–æ–¥ —Ç–æ–≤–∞—Ä—É."""
    max_code = 0
    for row in rows:
        if code_idx < len(row):
            try:
                code = int(row[code_idx])
                if code > max_code:
                    max_code = code
            except (ValueError, IndexError):
                continue
    return max_code


def get_characteristics_start_index(headers: List[str]) -> int:
    """–Ü–Ω–¥–µ–∫—Å –ø–æ—á–∞—Ç–∫—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (–ø—ñ—Å–ª—è "–î–µ_–∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è_—Ç–æ–≤–∞—Ä")."""
    try:
        return headers.index("–î–µ_–∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è_—Ç–æ–≤–∞—Ä") + 1
    except ValueError:
        return len(headers)


def merge_rows(old_row: List[str], new_row: List[str], 
               old_headers: List[str], availability_idx: int, 
               quantity_idx: int, chars_start_idx: int) -> List[str]:
    """–û–±'—î–¥–Ω—É—î —Ä—è–¥–∫–∏: –±–∞–∑–æ–≤—ñ –ø–æ–ª—è –∑—ñ —Å—Ç–∞—Ä–æ–≥–æ, –Ω–∞—è–≤–Ω—ñ—Å—Ç—å/–∫—ñ–ª—å–∫—ñ—Å—Ç—å/—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∑ –Ω–æ–≤–æ–≥–æ."""
    merged = old_row.copy()
    
    # –û–Ω–æ–≤–ª—é—î–º–æ –ù–∞—è–≤–Ω—ñ—Å—Ç—å —Ç–∞ –ö—ñ–ª—å–∫—ñ—Å—Ç—å
    if availability_idx < len(new_row) and availability_idx < len(merged):
        merged[availability_idx] = new_row[availability_idx]
    
    if quantity_idx < len(new_row) and quantity_idx < len(merged):
        merged[quantity_idx] = new_row[quantity_idx]
    
    # –ó–∞–º—ñ–Ω—è—î–º–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    merged = merged[:chars_start_idx]
    if chars_start_idx < len(new_row):
        merged.extend(new_row[chars_start_idx:])
    
    # –î–æ–ø–æ–≤–Ω—é—î–º–æ –¥–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ—ó –¥–æ–≤–∂–∏–Ω–∏
    while len(merged) < len(old_headers):
        merged.append("")
    
    return merged


def process_supplier(supplier: str, product_type: str) -> None:
    """–û–±—Ä–æ–±–ª—è—î –æ–¥–Ω–æ–≥–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ –≤–∫–∞–∑–∞–Ω–∏–º —Ç–∏–ø–æ–º."""
    print(f"\n{'='*60}")
    print(f"üîÑ {supplier.upper()} - {product_type.upper()}")
    print(f"{'='*60}")
    
    base_path = r"C:\FullStack\Scrapy"
    
    # –®–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤
    export_file = os.path.join(base_path, "data", supplier, "export-products.csv")
    new_file = os.path.join(base_path, "output", f"{supplier}_{product_type}.csv")
    import_file = os.path.join(base_path, "data", supplier, "import_products.csv")
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤
    if not os.path.exists(export_file):
        print(f"‚ùå Export —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {export_file}")
        return
    
    if not os.path.exists(new_file):
        print(f"‚ùå {product_type.capitalize()} —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {new_file}")
        return
    
    # –ß–∏—Ç–∞—î–º–æ —Ñ–∞–π–ª–∏
    print("\nüìÇ –ß–∏—Ç–∞—î–º–æ export-products.csv...")
    old_rows, old_headers = read_csv_as_rows(export_file)
    
    print(f"\nüìÇ –ß–∏—Ç–∞—î–º–æ {product_type}.csv...")
    new_rows, new_headers = read_csv_as_rows(new_file)
    
    if not old_rows or not new_rows:
        print("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª–∏")
        return
    
    # –Ü–Ω–¥–µ–∫—Å–∏ –ø–æ–ª—ñ–≤
    name_idx = get_field_index(old_headers, "–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó")
    code_idx = get_field_index(old_headers, "–ö–æ–¥_—Ç–æ–≤–∞—Ä—É")
    availability_idx = get_field_index(old_headers, "–ù–∞—è–≤–Ω—ñ—Å—Ç—å")
    quantity_idx = get_field_index(old_headers, "–ö—ñ–ª—å–∫—ñ—Å—Ç—å")
    identifier_idx = get_field_index(old_headers, "–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É")
    chars_start_idx = get_characteristics_start_index(old_headers)
    
    if name_idx == -1:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–∫—É '–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó'")
        return
    
    if identifier_idx == -1:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–∫—É '–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É'")
        return
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫–∏ –ø–æ –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É (–∞—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞)
    old_products_dict: Dict[str, List[str]] = {}  # {identifier: row}
    old_no_identifier: List[str] = []
    old_duplicates: List[tuple[str, str]] = []
    
    for row in old_rows:
        if identifier_idx < len(row):
            identifier = row[identifier_idx].strip()
            
            if not identifier:
                product_name = row[name_idx].strip() if name_idx < len(row) else 'N/A'
                old_no_identifier.append(f"{product_name[:40]}... | –ö–æ–¥: {row[code_idx] if code_idx < len(row) else 'N/A'}")
            elif identifier in old_products_dict:
                product_name = row[name_idx].strip() if name_idx < len(row) else 'N/A'
                old_duplicates.append((product_name, identifier))
            else:
                old_products_dict[identifier] = row
    
    new_products_dict: Dict[str, List[str]] = {}  # {identifier: row}
    new_no_identifier: List[str] = []
    new_duplicates: List[tuple[str, str]] = []
    
    for row in new_rows:
        if identifier_idx < len(row):
            identifier = row[identifier_idx].strip()
            
            if not identifier:
                product_name = row[name_idx].strip() if name_idx < len(row) else 'N/A'
                new_no_identifier.append(f"{product_name[:40]}... | –ö–æ–¥: {row[code_idx] if code_idx < len(row) else 'N/A'}")
            elif identifier in new_products_dict:
                product_name = row[name_idx].strip() if name_idx < len(row) else 'N/A'
                new_duplicates.append((product_name, identifier))
            else:
                new_products_dict[identifier] = row
    
    print(f"\nüìä –°—Ç–∞—Ä–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤ (–∑ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–æ–º): {len(old_products_dict)}")
    print(f"üìä –ù–æ–≤–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤ (–∑ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–æ–º):  {len(new_products_dict)}")
    
    # –í–∏–≤–æ–¥–∏–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é
    if old_no_identifier or old_duplicates or new_no_identifier or new_duplicates:
        print(f"\n{'-'*60}")
        print("‚ö†Ô∏è  –§–Ü–õ–¨–¢–†–ê–¶–Ü–Ø –¢–û–í–ê–†–Ü–í:")
        print(f"{'-'*60}")
        
        if old_no_identifier:
            print(f"\nüö´ –ë–µ–∑ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∞ –≤ export-products.csv: {len(old_no_identifier)}")
            for item in old_no_identifier[:5]:
                print(f"   - {item}")
            if len(old_no_identifier) > 5:
                print(f"   ... —Ç–∞ —â–µ {len(old_no_identifier) - 5}")
        
        if old_duplicates:
            print(f"\nüîÅ –î—É–±–ª—ñ–∫–∞—Ç–∏ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤ –≤ export-products.csv: {len(old_duplicates)}")
            for name, identifier in old_duplicates[:5]:
                print(f"   - '{name}' | ID: '{identifier}'")
            if len(old_duplicates) > 5:
                print(f"   ... —Ç–∞ —â–µ {len(old_duplicates) - 5}")
        
        if new_no_identifier:
            print(f"\nüö´ –ë–µ–∑ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∞ –≤ {product_type}.csv: {len(new_no_identifier)}")
            for item in new_no_identifier[:5]:
                print(f"   - {item}")
            if len(new_no_identifier) > 5:
                print(f"   ... —Ç–∞ —â–µ {len(new_no_identifier) - 5}")
        
        if new_duplicates:
            print(f"\nüîÅ –î—É–±–ª—ñ–∫–∞—Ç–∏ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤ –≤ {product_type}.csv: {len(new_duplicates)}")
            for name, identifier in new_duplicates[:5]:
                print(f"   - '{name}' | ID: '{identifier}'")
            if len(new_duplicates) > 5:
                print(f"   ... —Ç–∞ —â–µ {len(new_duplicates) - 5}")
        
        print(f"{'-'*60}")
    
    # –°–ø–∏—Å–æ–∫ –¥–ª—è —ñ–º–ø–æ—Ä—Ç—É
    import_rows: List[List[str]] = []
    processed_identifiers: Set[str] = set()  # –í—ñ–¥—Å—Ç–µ–∂—É—î–º–æ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∏
    
    stats = {
        'unchanged': 0,
        'qty_changed': 0,
        'availability_changed': 0,
        'both_changed': 0,
        'not_in_new': 0,
        'already_unavailable': 0,
        'new_products': 0
    }
    
    # –û–±—Ä–æ–±–∫–∞ —ñ—Å–Ω—É—é—á–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤ (–ø–æ—Ä—ñ–≤–Ω—é—î–º–æ –ø–æ –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É)
    for old_identifier, old_row in old_products_dict.items():
        processed_identifiers.add(old_identifier)
        
        if old_identifier in new_products_dict:
            new_row = new_products_dict[old_identifier]
            
            old_availability = old_row[availability_idx] if availability_idx < len(old_row) else ""
            new_availability = new_row[availability_idx] if availability_idx < len(new_row) else ""
            old_quantity = old_row[quantity_idx] if quantity_idx < len(old_row) else ""
            new_quantity = new_row[quantity_idx] if quantity_idx < len(new_row) else ""
            
            availability_changed = old_availability.strip() != new_availability.strip()
            quantity_changed = old_quantity.strip() != new_quantity.strip()
            
            if not availability_changed and not quantity_changed:
                stats['unchanged'] += 1
                continue
            
            updated_row = merge_rows(old_row, new_row, old_headers, 
                                    availability_idx, quantity_idx, chars_start_idx)
            
            if availability_changed and quantity_changed:
                stats['both_changed'] += 1
            elif quantity_changed:
                stats['qty_changed'] += 1
            elif availability_changed:
                stats['availability_changed'] += 1
            
            import_rows.append(updated_row)
            
        else:
            # –¢–æ–≤–∞—Ä –≤—ñ–¥—Å—É—Ç–Ω—ñ–π —É –Ω–æ–≤–æ–º—É - –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –≤—ñ–Ω –≤–∂–µ –±—É–≤ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π
            old_availability = old_row[availability_idx] if availability_idx < len(old_row) else ""
            old_quantity = old_row[quantity_idx] if quantity_idx < len(old_row) else ""
            
            # –Ø–∫—â–æ —Ç–æ–≤–∞—Ä –£–ñ–ï –±—É–≤ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π - –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ (–Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ –æ–Ω–æ–≤–ª—é–≤–∞—Ç–∏)
            if old_availability.strip() == "-" and old_quantity.strip() == "0":
                stats['already_unavailable'] += 1
                continue
            
            # –¢–æ–≤–∞—Ä –±—É–≤ –≤ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ, –∞–ª–µ –∑–Ω–∏–∫ - –ø–æ–∑–Ω–∞—á–∞—î–º–æ —è–∫ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π
            updated_row = old_row.copy()
            if availability_idx < len(updated_row):
                updated_row[availability_idx] = "-"
            if quantity_idx < len(updated_row):
                updated_row[quantity_idx] = "0"
            import_rows.append(updated_row)
            stats['not_in_new'] += 1
    
    # –û–±—Ä–æ–±–∫–∞ –Ω–æ–≤–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤ (–ø–æ—Ä—ñ–≤–Ω—é—î–º–æ –ø–æ –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É)
    new_product_identifiers = set(new_products_dict.keys()) - processed_identifiers
    
    if new_product_identifiers:
        max_code = get_max_product_code(old_rows, code_idx)
        next_code = max_code + 1
        
        for new_identifier in sorted(new_product_identifiers):
            new_row = new_products_dict[new_identifier].copy()
            
            if code_idx < len(new_row):
                new_row[code_idx] = str(next_code)
            
            while len(new_row) < len(old_headers):
                new_row.append("")
            
            import_rows.append(new_row)
            next_code += 1
            stats['new_products'] += 1
    
    # –ó–∞–ø–∏—Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
    try:
        os.makedirs(os.path.dirname(import_file), exist_ok=True)
        
        with open(import_file, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f, delimiter=';')
            writer.writerow(old_headers)
            
            for row in import_rows:
                row = row[:len(old_headers)]
                writer.writerow(row)
        
        print(f"\n‚úÖ –§–∞–π–ª —Å—Ç–≤–æ—Ä–µ–Ω–æ: {import_file}")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Å—É: {e}")
        return
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\n{'='*60}")
    print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"{'='*60}")
    print(f"  –ë–µ–∑ –∑–º—ñ–Ω:                {stats['unchanged']}")
    print(f"  –ó–º—ñ–Ω–∏–ª–∞—Å—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å:     {stats['qty_changed']}")
    print(f"  –ó–º—ñ–Ω–∏–ª–∞—Å—è –Ω–∞—è–≤–Ω—ñ—Å—Ç—å:     {stats['availability_changed']}")
    print(f"  –ó–º—ñ–Ω–∏–ª–æ—Å—è –æ–±–∏–¥–≤–∞:        {stats['both_changed']}")
    print(f"  –í—ñ–¥—Å—É—Ç–Ω—ñ –≤ –Ω–æ–≤–æ–º—É:       {stats['not_in_new']}")
    print(f"  –í–∂–µ –±—É–ª–∏ –≤—ñ–¥—Å—É—Ç–Ω—ñ:      {stats['already_unavailable']}")
    print(f"  –ù–æ–≤—ñ —Ç–æ–≤–∞—Ä–∏:             {stats['new_products']}")
    print(f"{'-'*60}")
    print(f"  –í–°–¨–û–ì–û –¥–ª—è —ñ–º–ø–æ—Ä—Ç—É:      {len(import_rows)}")
    print(f"{'='*60}")


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è."""
    print("="*60)
    print("üöÄ –£–ù–Ü–í–ï–†–°–ê–õ–¨–ù–ò–ô –°–ö–†–ò–ü–¢ –û–ù–û–í–õ–ï–ù–ù–Ø –¢–û–í–ê–†–Ü–í")
    print("   (–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø–æ –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É)")
    print("="*60)
    
    # –ë–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç—ñ–≤ - –æ–±—Ä–æ–±–∏—Ç–∏ –≤—Å—ñ—Ö
    if len(sys.argv) == 1:
        print("\nüì¶ –û–±—Ä–æ–±–∫–∞ –≤—Å—ñ—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤...")
        for supplier in SUPPLIERS:
            for product_type in TYPES:
                try:
                    process_supplier(supplier, product_type)
                except Exception as e:
                    print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ {supplier} {product_type}: {e}")
        print("\n‚úÖ –í–°–Ü –ü–û–°–¢–ê–ß–ê–õ–¨–ù–ò–ö–ò –û–ë–†–û–ë–õ–ï–ù–û")
        return
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç—ñ–≤
    if len(sys.argv) < 3:
        print("\n‚ùå –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è: python update_products.py <supplier> <type>")
        print(f"\n–ü–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∏: {', '.join(SUPPLIERS)}")
        print(f"–¢–∏–ø–∏: {', '.join(TYPES)}")
        print("\n–ü—Ä–∏–∫–ª–∞–¥–∏:")
        print("  python update_products.py                  # –í—Å—ñ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∏")
        print("  python update_products.py viatec dealer")
        print("  python update_products.py viatec retail")
        sys.exit(1)
    
    supplier = sys.argv[1].lower()
    product_type = sys.argv[2].lower()
    
    if supplier not in SUPPLIERS:
        print(f"‚ùå –ù–µ–≤—ñ–¥–æ–º–∏–π –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫: {supplier}")
        print(f"–î–æ—Å—Ç—É–ø–Ω—ñ: {', '.join(SUPPLIERS)}")
        sys.exit(1)
    
    if product_type not in TYPES:
        print(f"‚ùå –ù–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø: {product_type}")
        print(f"–î–æ—Å—Ç—É–ø–Ω—ñ: {', '.join(TYPES)}")
        sys.exit(1)
    
    process_supplier(supplier, product_type)
    print("\n‚úÖ –ó–ê–í–ï–†–®–ï–ù–û")


if __name__ == "__main__":
    main()
