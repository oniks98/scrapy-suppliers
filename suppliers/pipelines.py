"""
–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π Pipeline –¥–ª—è –≤—Å—ñ—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤.
–û–¥–∏–Ω pipeline –∫–µ—Ä—É—î –∑–∞–ø–∏—Å–æ–º —É —Ä—ñ–∑–Ω—ñ CSV —Ñ–∞–π–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ supplier_id —Ç–∞ output_file.

–§–Ü–õ–¨–¢–†–ê–¶–Ü–Ø:
- –ü—Ä–æ–ø—É—Å–∫–∞—î —Ç–æ–≤–∞—Ä–∏ –ë–ï–ó —Ü—ñ–Ω–∏
- –ü—Ä–æ–ø—É—Å–∫–∞—î —Ç–æ–≤–∞—Ä–∏ –ù–ï –í –ù–ê–Ø–í–ù–û–°–¢–Ü
- "–í –Ω–∞–ª–∏—á–∏–∏" ‚Üí "+"
- "–í –Ω–∞–ª–∏—á–∏–∏ 5 —à—Ç" ‚Üí –ù–∞—è–≤–Ω—ñ—Å—Ç—å: "+", –ö—ñ–ª—å–∫—ñ—Å—Ç—å: "5"

–•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é rule_kind:
- extract: –æ—Å–Ω–æ–≤–Ω–µ –ø—Ä–∞–≤–∏–ª–æ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è (–ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –ø–æ priority)
- normalize: –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ñ–æ—Ä–º–∞—Ç—É (–ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –ø–æ priority)
- derive: –ª–æ–≥—ñ—á–Ω–∏–π –≤–∏–≤—ñ–¥ (–ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—É—î extract/normalize)
- fallback: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –∑–Ω–∞—á–µ–Ω–Ω—è –≤—ñ–¥—Å—É—Ç–Ω—î
- skip: –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ —Ü—é —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É

–§–æ—Ä–º–∞—Ç PROM: –ø–æ–≤—Ç–æ—Ä—é–≤–∞–Ω—ñ —Ç—Ä–∏–ø–ª–µ—Ç–∏ –ë–ï–ó –Ω—É–º–µ—Ä–∞—Ü—ñ—ó
- –ù–∞–∑–≤–∞_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏;–û–¥–∏–Ω–∏—Ü—è_–≤–∏–º—ñ—Ä—É_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏;–ó–Ω–∞—á–µ–Ω–Ω—è_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (x160 —Ä–∞–∑—ñ–≤)
"""
import re
import csv
from pathlib import Path
from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem
from suppliers.attribute_mapper import AttributeMapper


class SuppliersPipeline:
    """–û–¥–∏–Ω pipeline –¥–ª—è –≤—Å—ñ—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é rule_kind"""
    
    def __init__(self):
        self.files = {}
        self.writers = {}
        self.viatec_dealer_coefficient_mapping = {}
        self.personal_notes_mapping = {}
        self.label_mapping = {}
        self.attribute_mapper = None
        
        # –ë–∞–∑–æ–≤—ñ –ø–æ–ª—è CSV –∑–≥—ñ–¥–Ω–æ —Ñ–æ—Ä–º–∞—Ç—É PROM
        self.fieldnames_base = [
            "–ö–æ–¥_—Ç–æ–≤–∞—Ä—É",
            "–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó",
            "–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó_—É–∫—Ä",
            "–ü–æ—à—É–∫–æ–≤—ñ_–∑–∞–ø–∏—Ç–∏",
            "–ü–æ—à—É–∫–æ–≤—ñ_–∑–∞–ø–∏—Ç–∏_—É–∫—Ä",
            "–û–ø–∏—Å",
            "–û–ø–∏—Å_—É–∫—Ä",
            "–¢–∏–ø_—Ç–æ–≤–∞—Ä—É",
            "–¶—ñ–Ω–∞",
            "–í–∞–ª—é—Ç–∞",
            "–û–¥–∏–Ω–∏—Ü—è_–≤–∏–º—ñ—Ä—É",
            "–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π_–æ–±—Å—è–≥_–∑–∞–º–æ–≤–ª–µ–Ω–Ω—è",
            "–û–ø—Ç–æ–≤–∞_—Ü—ñ–Ω–∞",
            "–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–µ_–∑–∞–º–æ–≤–ª–µ–Ω–Ω—è_–æ–ø—Ç",
            "–ü–æ—Å–∏–ª–∞–Ω–Ω—è_–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è",
            "–ù–∞—è–≤–Ω—ñ—Å—Ç—å",
            "–ö—ñ–ª—å–∫—ñ—Å—Ç—å",
            "–ù–æ–º–µ—Ä_–≥—Ä—É–ø–∏",
            "–ù–∞–∑–≤–∞_–≥—Ä—É–ø–∏",
            "–ü–æ—Å–∏–ª–∞–Ω–Ω—è_–ø—ñ–¥—Ä–æ–∑–¥—ñ–ª—É",
            "–ú–æ–∂–ª–∏–≤—ñ—Å—Ç—å_–ø–æ—Å—Ç–∞–≤–∫–∏",
            "–¢–µ—Ä–º—ñ–Ω_–ø–æ—Å—Ç–∞–≤–∫–∏",
            "–°–ø–æ—Å—ñ–±_–ø–∞–∫—É–≤–∞–Ω–Ω—è",
            "–°–ø–æ—Å—ñ–±_–ø–∞–∫—É–≤–∞–Ω–Ω—è_—É–∫—Ä",
            "–£–Ω—ñ–∫–∞–ª—å–Ω–∏–π_—ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä",
            "–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É",
            "–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_–ø—ñ–¥—Ä–æ–∑–¥—ñ–ª—É",
            "–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_–≥—Ä—É–ø–∏",
            "–í–∏—Ä–æ–±–Ω–∏–∫",
            "–ö—Ä–∞—ó–Ω–∞_–≤–∏—Ä–æ–±–Ω–∏–∫",
            "–ó–Ω–∏–∂–∫–∞",
            "ID_–≥—Ä—É–ø–∏_—Ä—ñ–∑–Ω–æ–≤–∏–¥—ñ–≤",
            "–û—Å–æ–±–∏—Å—Ç—ñ_–Ω–æ—Ç–∞—Ç–∫–∏",
            "–ü—Ä–æ–¥—É–∫—Ç_–Ω–∞_—Å–∞–π—Ç—ñ",
            "–¢–µ—Ä–º—ñ–Ω_–¥—ñ—ó_–∑–Ω–∏–∂–∫–∏_–≤—ñ–¥",
            "–¢–µ—Ä–º—ñ–Ω_–¥—ñ—ó_–∑–Ω–∏–∂–∫–∏_–¥–æ",
            "–¶—ñ–Ω–∞_–≤—ñ–¥",
            "–Ø—Ä–ª–∏–∫",
            "HTML_–∑–∞–≥–æ–ª–æ–≤–æ–∫",
            "HTML_–∑–∞–≥–æ–ª–æ–≤–æ–∫_—É–∫—Ä",
            "HTML_–æ–ø–∏—Å",
            "HTML_–æ–ø–∏—Å_—É–∫—Ä",
            "–ö–æ–¥_–º–∞—Ä–∫—É–≤–∞–Ω–Ω—è_(GTIN)",
            "–ù–æ–º–µ—Ä_–ø—Ä–∏—Å—Ç—Ä–æ—é_(MPN)",
            "–í–∞–≥–∞,–∫–≥",
            "–®–∏—Ä–∏–Ω–∞,—Å–º",
            "–í–∏—Å–æ—Ç–∞,—Å–º",
            "–î–æ–≤–∂–∏–Ω–∞,—Å–º",
            "–î–µ_–∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è_—Ç–æ–≤–∞—Ä",
        ]
        
        self.output_dir = Path(r"C:\FullStack\Scrapy\output")
        self.product_counters = {}
        self.stats = {}
    
    def open_spider(self, spider):
        """–°—Ç–≤–æ—Ä—é—î–º–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é output —Ç–∞ —Ñ–∞–π–ª –ø—Ä–∏ –≤—ñ–¥–∫—Ä–∏—Ç—Ç—ñ –ø–∞—É–∫–∞"""
        self.output_dir.mkdir(parents=True, exist_ok=True)
        spider.logger.info(f"‚úÖ Pipeline –≤—ñ–¥–∫—Ä–∏—Ç–æ –¥–ª—è {spider.name}")
        spider.logger.info(f"üìÅ –í–∏—Ö—ñ–¥–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è: {self.output_dir}")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–∞–ø—ñ–Ω–≥—É –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤ (—Ç—ñ–ª—å–∫–∏ –¥–ª—è viatec_dealer)
        if spider.name == 'viatec_dealer':
            coefficient_path = r"C:\FullStack\Scrapy\data\viatec\viatec_coefficient_dealer.csv"
            try:
                with open(coefficient_path, 'r', encoding='utf-8-sig') as f:
                    reader = csv.reader(f, delimiter=';')
                    next(reader)  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    
                    for row in reader:
                        if len(row) >= 3:
                            url = row[1].strip()
                            coefficient_str = row[2].strip().replace(',', '.')
                            try:
                                coefficient = float(coefficient_str)
                                self.viatec_dealer_coefficient_mapping[url] = coefficient
                                spider.logger.debug(f"–ú–∞–ø—ñ–Ω–≥: {url} ‚Üí {coefficient}")
                            except ValueError:
                                spider.logger.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –¥–ª—è {url}: {coefficient_str}")
                
                spider.logger.info(
                    f"‚úÖ –ú–∞–ø—ñ–Ω–≥ –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤ –¥–ª—è viatec_dealer –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: "
                    f"{len(self.viatec_dealer_coefficient_mapping)} URL"
                )
                        
            except FileNotFoundError:
                spider.logger.error(f"‚ùå –§–∞–π–ª –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {coefficient_path}")
            except Exception as e:
                spider.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤ –¥–ª—è viatec_dealer: {e}")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –æ—Å–æ–±–∏—Å—Ç–∏—Ö –Ω–æ—Ç–∞—Ç–æ–∫ —Ç–∞ —è—Ä–ª–∏–∫—ñ–≤
        supplier_name = spider.name.split('_')[0]
        personal_notes_path = Path(r"C:\FullStack\Scrapy\data") / supplier_name / f"{supplier_name}_personal_notes.csv"
        
        try:
            with open(personal_notes_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f, delimiter=';')
                next(reader)
                for row in reader:
                    if len(row) >= 2:
                        group_number = row[0].strip()
                        personal_note_value = row[1].strip()
                        label_value = row[2].strip() if len(row) >= 3 else ""
                        
                        self.personal_notes_mapping[group_number] = personal_note_value
                        self.label_mapping[group_number] = label_value
            
            spider.logger.info(f"‚úÖ –ú–∞–ø—ñ–Ω–≥ –æ—Å–æ–±–∏—Å—Ç–∏—Ö –Ω–æ—Ç–∞—Ç–æ–∫: {len(self.personal_notes_mapping)} –∑–∞–ø–∏—Å—ñ–≤")
            spider.logger.info(f"‚úÖ –ú–∞–ø—ñ–Ω–≥ —è—Ä–ª–∏–∫—ñ–≤: {len(self.label_mapping)} –∑–∞–ø–∏—Å—ñ–≤")
        except FileNotFoundError:
            spider.logger.warning(f"‚ö†Ô∏è  –§–∞–π–ª –æ—Å–æ–±–∏—Å—Ç–∏—Ö –Ω–æ—Ç–∞—Ç–æ–∫ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {personal_notes_path}")
        except Exception as e:
            spider.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–∞–ø—ñ–Ω–≥—É: {e}")

        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–∞–ø–ø–µ—Ä–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        rules_path = Path(r"C:\FullStack\Scrapy\data") / supplier_name / f"{supplier_name}_mapping_rules.csv"
        if rules_path.exists():
            try:
                self.attribute_mapper = AttributeMapper(str(rules_path), spider.logger)
                spider.logger.info(f"‚úÖ AttributeMapper —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")
            except Exception as e:
                spider.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó AttributeMapper: {e}")
                self.attribute_mapper = None
        else:
            spider.logger.warning(f"‚ö†Ô∏è  –ú–∞–ø–ø—ñ–Ω–≥ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤—ñ–¥–∫–ª—é—á–µ–Ω–æ")
            self.attribute_mapper = None

        output_file = getattr(spider, 'output_filename', f"{spider.name}.csv")
        filepath = self.output_dir / output_file
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—É
        try:
            test_file = open(filepath, "a", encoding="utf-8")
            test_file.close()
        except PermissionError:
            spider.logger.error(f"‚ùå –§–∞–π–ª {filepath} –≤—ñ–¥–∫—Ä–∏—Ç–∏–π –≤ —ñ–Ω—à—ñ–π –ø—Ä–æ–≥—Ä–∞–º—ñ!")
            raise PermissionError(f"–ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–ø–∏—Å–∞—Ç–∏ —É —Ñ–∞–π–ª {filepath}")
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ñ–∞–π–ª—É
        try:
            self.files[output_file] = open(filepath, "w", encoding="utf-8-sig", newline="", buffering=1)
            self._write_header(self.files[output_file])
            spider.logger.info(f"üìù –°—Ç–≤–æ—Ä–µ–Ω–æ —Ñ–∞–π–ª: {filepath}")
        except Exception as e:
            spider.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ñ–∞–π–ª—É: {e}")
            raise
        
        self.product_counters[output_file] = self._load_initial_product_code(spider.name, spider.logger)
        self.stats[output_file] = {
            "count": 0,
            "filtered_no_price": 0,
            "filtered_no_stock": 0,
        }
    
    def process_item(self, item, spider):
        """–û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω item –∑ –§–Ü–õ–¨–¢–†–ê–¶–Ü–Ñ–Æ"""
        adapter = ItemAdapter(item)
        output_file = adapter.get("output_file") or f"{adapter.get('supplier_id', 'unknown')}.csv"
        
        # –§–Ü–õ–¨–¢–† 1: –¶—ñ–Ω–∞
        price = adapter.get("–¶—ñ–Ω–∞", "")
        if not price or not self._is_valid_price(price):
            self._increment_stat(output_file, "filtered_no_price")
            product_name = adapter.get('–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó', '–ù–µ–≤—ñ–¥–æ–º–∏–π')[:60]
            spider.logger.warning(f"‚ùå –¢–æ–≤–∞—Ä –±–µ–∑ —Ü—ñ–Ω–∏: {product_name}...")
            raise DropItem("–¢–æ–≤–∞—Ä –±–µ–∑ —Ü—ñ–Ω–∏")
        
        # –§–Ü–õ–¨–¢–† 2: –ù–∞—è–≤–Ω—ñ—Å—Ç—å
        availability_raw = adapter.get("–ù–∞—è–≤–Ω—ñ—Å—Ç—å", "")
        if not self._check_availability(availability_raw):
            self._increment_stat(output_file, "filtered_no_stock")
            product_name = adapter.get('–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó', '–ù–µ–≤—ñ–¥–æ–º–∏–π')[:60]
            spider.logger.warning(f"‚ùå –¢–æ–≤–∞—Ä –Ω–µ –≤ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ: {product_name}...")
            raise DropItem("–¢–æ–≤–∞—Ä –Ω–µ –≤ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ")
        
        cleaned_item = self._clean_item(adapter, spider)
        
        # –ú–Ω–æ–∂–µ–Ω–Ω—è —Ü—ñ–Ω–∏ –¥–ª—è viatec_dealer
        if spider.name == 'viatec_dealer' and self.viatec_dealer_coefficient_mapping:
            category_url = adapter.get('category_url', '')
            coefficient = self.viatec_dealer_coefficient_mapping.get(category_url)
            
            if coefficient:
                try:
                    price_float = float(cleaned_item["–¶—ñ–Ω–∞"].replace(',', '.'))
                    multiplied_price = price_float * coefficient
                    cleaned_item["–¶—ñ–Ω–∞"] = f"{multiplied_price:.2f}".replace('.', ',')
                except (ValueError, TypeError) as e:
                    spider.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –º–Ω–æ–∂–µ–Ω–Ω—è —Ü—ñ–Ω–∏: {e}")

        cleaned_item["–ù–∞—è–≤–Ω—ñ—Å—Ç—å"] = "+"
        cleaned_item["–ö—ñ–ª—å–∫—ñ—Å—Ç—å"] = adapter.get("–ö—ñ–ª—å–∫—ñ—Å—Ç—å", "") or "100"
        
        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∫–æ–¥—É —Ç–æ–≤–∞—Ä—É
        if output_file not in self.product_counters:
            self.product_counters[output_file] = self._load_initial_product_code(spider.name, spider.logger)
        
        cleaned_item["–ö–æ–¥_—Ç–æ–≤–∞—Ä—É"] = str(self.product_counters[output_file])
        self.product_counters[output_file] += 1
        
        cleaned_item["–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É"] = adapter.get("–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_—Ç–æ–≤–∞—Ä—É", "").strip()
        
        # –û—Å–æ–±–∏—Å—Ç—ñ –Ω–æ—Ç–∞—Ç–∫–∏ —Ç–∞ —è—Ä–ª–∏–∫–∏
        group_number = adapter.get("–ù–æ–º–µ—Ä_–≥—Ä—É–ø–∏", "")
        cleaned_item["–û—Å–æ–±–∏—Å—Ç—ñ_–Ω–æ—Ç–∞—Ç–∫–∏"] = self.personal_notes_mapping.get(group_number, "PROM")
        cleaned_item["–Ø—Ä–ª–∏–∫"] = self.label_mapping.get(group_number, "")
        
        # –û–ø–∏—Å
        cleaned_item["–û–ø–∏—Å"] = self._clean_description(cleaned_item.get("–û–ø–∏—Å", ""))
        cleaned_item["–û–ø–∏—Å_—É–∫—Ä"] = self._clean_description(cleaned_item.get("–û–ø–∏—Å_—É–∫—Ä", ""))
        
        # –°–∞–Ω—ñ—Ç–∏–∑–∞—Ü—ñ—è URL –∑–æ–±—Ä–∞–∂–µ–Ω—å
        image_url = cleaned_item.get("–ü–æ—Å–∏–ª–∞–Ω–Ω—è_–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", "")
        if image_url:
            urls = [u.strip() for u in image_url.split(", ") if u.strip()]
            sanitized_urls = [url.replace(",", "%2C") if ',' in url else url for url in urls]
            cleaned_item["–ü–æ—Å–∏–ª–∞–Ω–Ω—è_–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è"] = ", ".join(sanitized_urls)
        
        # –û–±—Ä–æ–±–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        specs_list_original = adapter.get("specifications_list", [])
        
        if self.attribute_mapper:
            category_id = adapter.get("–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_–ø—ñ–¥—Ä–æ–∑–¥—ñ–ª—É", "")
            product_name = cleaned_item.get('–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó', '')
            
            # –ú–∞–ø—ñ–Ω–≥ –∑ –Ω–∞–∑–≤–∏ —Ç–æ–≤–∞—Ä—É
            name_mapped = []
            if product_name:
                name_mapped = self.attribute_mapper.map_product_name(product_name, category_id)
            
            # –ú–∞–ø—ñ–Ω–≥ –∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            mapping_result = {'supplier': [], 'mapped': [], 'unmapped': []}
            if specs_list_original:
                mapping_result = self.attribute_mapper.map_attributes(specs_list_original, category_id)
            
            # –û–±'—î–¥–Ω–∞–Ω–Ω—è –∑ –¥–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—î—é
            specs_dict = {}
            
            for spec in mapping_result['supplier']:
                key = spec['name'].lower().strip()
                if key not in specs_dict:
                    specs_dict[key] = {**spec, 'rule_priority': 9999, 'rule_kind': 'supplier'}
            
            for spec in mapping_result['mapped']:
                rule_kind = spec.get('rule_kind', 'extract')
                if rule_kind == 'skip':
                    continue
                
                key = spec['name'].lower().strip()
                if key not in specs_dict or self._should_replace_attribute(
                    rule_kind, spec.get('rule_priority', 999),
                    specs_dict[key].get('rule_kind', 'extract'),
                    specs_dict[key].get('rule_priority', 999)
                ):
                    specs_dict[key] = spec
            
            for spec in name_mapped:
                rule_kind = spec.get('rule_kind', 'extract')
                if rule_kind == 'skip':
                    continue
                
                key = spec['name'].lower().strip()
                if key not in specs_dict or self._should_replace_attribute(
                    rule_kind, spec.get('rule_priority', 999),
                    specs_dict[key].get('rule_kind', 'extract'),
                    specs_dict[key].get('rule_priority', 999)
                ):
                    specs_dict[key] = spec
            
            specs_list = list(specs_dict.values())
            
            # –ü–æ—Å—Ç–æ–±—Ä–æ–±–∫–∞
            specs_list = self._postprocess_weight_in_specs(specs_list, spider)
            specs_list = self._postprocess_hdd_capacity_in_specs(specs_list, spider)
            specs_list = self._postprocess_battery_capacity_in_specs(specs_list, spider)
        else:
            specs_list = specs_list_original
        
        # –í–∏—Ç—è–≥—É—î–º–æ –≥–∞–±–∞—Ä–∏—Ç–∏ –∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ PROM (–ø—ñ—Å–ª—è –≤—Å—ñ—Ö –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—ñ–≤)
        dimensions = self._extract_dimensions_from_specs(specs_list, spider)
        cleaned_item.update(dimensions)
        
        # –ó–∞–ø–∏—Å —É —Ñ–∞–π–ª
        if output_file not in self.files:
            raise ValueError(f"File {output_file} was not initialized")
        
        row_parts = []
        for field in self.fieldnames_base:
            value = cleaned_item.get(field, "")
            value_str = str(value).replace(";", ",").replace('"', '‚Ä≥').replace("\n", "<br>").replace("\r", "")
            row_parts.append(value_str)
        
        for i in range(160):
            if i < len(specs_list):
                spec = specs_list[i]
                name = str(spec.get("name", "")).replace(";", ",").replace('"', '‚Ä≥').replace("\n", "<br>").replace("\r", "")
                unit = str(spec.get("unit", "")).replace(";", ",").replace('"', '‚Ä≥').replace("\n", "<br>").replace("\r", "")
                value = str(spec.get("value", "")).replace(";", ",").replace('"', '‚Ä≥').replace("\n", "<br>").replace("\r", "")
                row_parts.extend([name, unit, value])
            else:
                row_parts.extend(["", "", ""])
        
        self.files[output_file].write(";".join(row_parts) + "\n")
        self.stats[output_file]["count"] += 1
        
        return item
    
    def _should_replace_attribute(self, new_kind, new_priority, current_kind, current_priority):
        """–í–∏–∑–Ω–∞—á–∞—î —á–∏ —Ç—Ä–µ–±–∞ –∑–∞–º—ñ–Ω–∏—Ç–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É"""
        if new_kind in ['skip', 'fallback']:
            return False
        if new_kind == 'derive':
            return current_kind == 'derive' and new_priority < current_priority
        return new_priority < current_priority
    
    def close_spider(self, spider):
        """–ó–∞–∫—Ä–∏—Ç—Ç—è —Ñ–∞–π–ª—ñ–≤ —Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
        for f in self.files.values():
            f.close()
        
        spider.logger.info("=" * 80)
        spider.logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê PIPELINE")
        spider.logger.info("=" * 80)
        
        for output_file, stats in self.stats.items():
            spider.logger.info(f"\nüìÑ –§–∞–π–ª: {output_file}")
            spider.logger.info(f"  ‚úÖ –¢–æ–≤–∞—Ä—ñ–≤ –∑–∞–ø–∏—Å–∞–Ω–æ: {stats['count']}")
            spider.logger.info(f"  ‚ùå –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –±–µ–∑ —Ü—ñ–Ω–∏: {stats['filtered_no_price']}")
            spider.logger.info(f"  ‚ùå –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –±–µ–∑ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ: {stats['filtered_no_stock']}")
        
        spider.logger.info("=" * 80)
    
    def _write_header(self, file_obj):
        """–ó–∞–ø–∏—Å –∑–∞–≥–æ–ª–æ–≤–∫—É"""
        header_parts = self.fieldnames_base.copy()
        for _ in range(160):
            header_parts.extend([
                "–ù–∞–∑–≤–∞_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
                "–û–¥–∏–Ω–∏—Ü—è_–≤–∏–º—ñ—Ä—É_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
                "–ó–Ω–∞—á–µ–Ω–Ω—è_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
            ])
        file_obj.write(";".join(header_parts) + "\n")
    
    def _is_valid_price(self, price):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ü—ñ–Ω–∏"""
        if not price:
            return False
        try:
            price_float = float(str(price).replace(",", ".").replace(" ", ""))
            return price_float > 0
        except (ValueError, TypeError):
            return False
    
    def _check_availability(self, availability_str):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ"""
        if not availability_str:
            return True
        
        availability_lower = str(availability_str).lower().strip()
        
        out_of_stock_keywords = [
            "–Ω–µ–º–∞—î", "–Ω–µ–º–∞—î –≤ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ", "–Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏", "–Ω–µ—Ç –Ω–∞ —Å–∫–ª–∞–¥–µ",
            "–≤—ñ–¥—Å—É—Ç–Ω—ñ–π", "–≤—ñ–¥—Å—É—Ç–Ω—è", "–∑–∞–∫—ñ–Ω—á–∏–≤—Å—è", "–∑–∞–∫—ñ–Ω—á–∏–ª–∞—Å—å",
            "out of stock", "unavailable", "–ø–æ–¥ –∑–∞–∫–∞–∑", "–ø—ñ–¥ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è",
        ]
        
        for keyword in out_of_stock_keywords:
            if keyword in availability_lower:
                return False
        
        return True
    
    def _clean_description(self, description):
        """–û—á–∏—â–µ–Ω–Ω—è –æ–ø–∏—Å—É"""
        if not description:
            return ""
        
        patterns_to_remove = [
            r"–Ñ —Ç–æ–≤–∞—Ä–∏ –∑ –∞–Ω–∞–ª–æ–≥—ñ—á–Ω–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏\s*‚Üí",
            r"–ï—Å—Ç—å —Ç–æ–≤–∞—Ä—ã —Å –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏\s*‚Üí",
        ]
        
        for pattern in patterns_to_remove:
            description = re.sub(pattern, "", description, flags=re.IGNORECASE)
        
        description = description.replace("\n", "<br>")
        description = re.sub(r' +', ' ', description)
        
        return description.strip()
    
    def _clean_item(self, adapter, spider):
        """–û—á–∏—â–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö"""
        cleaned = {}
        
        for field in self.fieldnames_base:
            value = adapter.get(field, "")
            
            if isinstance(value, str):
                value = value.strip()
            
            if field == "–¶—ñ–Ω–∞":
                value = self._clean_price(value)
            elif field == "–í–∞–ª—é—Ç–∞":
                value = value.upper() if value else "UAH"
            elif field == "–û–¥–∏–Ω–∏—Ü—è_–≤–∏–º—ñ—Ä—É":
                value = value if value else "—à—Ç."
            elif field == "–í–∞–≥–∞,–∫–≥":
                value = self._convert_weight_to_grams(value)
            
            cleaned[field] = value
        
        return cleaned
    
    def _clean_price(self, price):
        """–û—á–∏—â–µ–Ω–Ω—è —Ü—ñ–Ω–∏"""
        if not price:
            return ""
        
        price_str = str(price).replace(",", ".").replace(" ", "")
        price_str = price_str.replace("–≥—Ä–Ω", "").replace("‚Ç¥", "").replace("$", "").replace("USD", "")
        
        try:
            cleaned = "".join(c for c in price_str if c.isdigit() or c == ".")
            if cleaned:
                price_float = float(cleaned)
                return str(price_float).replace(".", ",")
            return ""
        except ValueError:
            return ""
    
    def _convert_weight_to_grams(self, weight_str):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤–∞–≥–∏ –≤ –≥—Ä–∞–º–∏"""
        if not weight_str:
            return ""
        
        weight_str = str(weight_str).strip()
        
        match_g = re.search(r'(?:–í–∞–≥–∞\s+)?([0-9\.]+)\s*–≥', weight_str, re.IGNORECASE)
        if match_g:
            return match_g.group(1)
        
        match_kg = re.search(r'(?:–í–∞–≥–∞\s+)?([0-9\.]+)\s*–∫–≥', weight_str, re.IGNORECASE)
        if match_kg:
            kg = float(match_kg.group(1))
            grams = kg * 1000
            return str(int(grams)) if grams == int(grams) else str(grams)
        
        return weight_str
    
    def _postprocess_weight_in_specs(self, specs_list, spider):
        """–ü–æ—Å—Ç–æ–±—Ä–æ–±–∫–∞ –≤–∞–≥–∏ –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö"""
        if not specs_list:
            return specs_list
        
        weight_names = ['–≤–∞–≥–∞', '–≤–∞–≥–∞ –±—Ä—É—Ç—Ç–æ', '–≤–∞–≥–∞ –Ω–µ—Ç—Ç–æ', 'weight', 'gross weight', 'net weight']
        
        for spec in specs_list:
            if spec.get('name', '').lower().strip() in weight_names:
                original_value = spec.get('value', '')
                converted_value = self._convert_weight_to_grams(original_value)
                if converted_value != original_value:
                    spec['value'] = converted_value
                    spider.logger.info(f"‚öñÔ∏è –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤–∞–≥–∏: {spec['name']} = '{original_value}' ‚Üí '{converted_value}'")
        
        return specs_list
    
    def _postprocess_hdd_capacity_in_specs(self, specs_list, spider):
        """–ü–æ—Å—Ç–æ–±—Ä–æ–±–∫–∞ —î–º–Ω–æ—Å—Ç—ñ HDD"""
        if not specs_list:
            return specs_list
        
        hdd_names = ['—Å—É–º–º–∞—Ä–Ω–∞—è –µ–º–∫–æ—Å—Ç—å hdd', 'total hdd capacity', '–∑–∞–≥–∞–ª—å–Ω–∞ —î–º–Ω—ñ—Å—Ç—å hdd']
        disk_names = ['–æ–±\'—î–º –Ω–∞–∫–æ–ø–∏—á—É–≤–∞—á–∞', 'disk capacity', '—î–º–Ω—ñ—Å—Ç—å –¥–∏—Å–∫–∞']
        
        for spec in specs_list:
            spec_name_lower = spec.get('name', '').lower().strip()
            original_value = spec.get('value', '')
            
            if spec_name_lower in hdd_names:
                match = re.search(r'(\d+)\s*SATA\s*(\d+)\s*–¢–±', original_value, re.IGNORECASE)
                if match:
                    try:
                        num_sata = int(match.group(1))
                        max_tb = int(match.group(2))
                        total_gb = num_sata * max_tb * 1024
                        spec['value'] = str(total_gb)
                        spider.logger.info(f"üíæ HDD: '{original_value}' ‚Üí '{total_gb} GB'")
                    except (ValueError, AttributeError) as e:
                        spider.logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ HDD: {e}")
            
            elif spec_name_lower in disk_names:
                match = re.search(r'(\d+)\s*[–¢—Ç][–ë–±Bb]', original_value, re.IGNORECASE)
                if match:
                    try:
                        tb_value = int(match.group(1))
                        gb_value = tb_value * 1024
                        spec['value'] = str(gb_value)
                        spider.logger.info(f"üíæ –î–∏—Å–∫: '{original_value}' ‚Üí '{gb_value} GB'")
                    except (ValueError, AttributeError) as e:
                        spider.logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –¥–∏—Å–∫: {e}")
        
        return specs_list
    
    def _postprocess_battery_capacity_in_specs(self, specs_list, spider):
        """–ü–æ—Å—Ç–æ–±—Ä–æ–±–∫–∞ —î–º–Ω–æ—Å—Ç—ñ –±–∞—Ç–∞—Ä–µ—ó"""
        if not specs_list:
            return specs_list
        
        battery_names = ['—î–º–Ω—ñ—Å—Ç—å –∞–∫—É–º—É–ª—è—Ç–æ—Ä—É', 'battery capacity', '–µ–º–∫–æ—Å—Ç—å –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä–∞']
        
        for spec in specs_list:
            if spec.get('name', '').lower().strip() in battery_names:
                original_value = spec.get('value', '')
                match = re.search(r'([\d\.]+)\s*[–êA](?:‚Ä¢|¬∑|–≥)?[–≥—á]?', original_value, re.IGNORECASE)
                if match:
                    try:
                        ah_value = float(match.group(1))
                        mah_value = int(ah_value * 1000)
                        spec['value'] = str(mah_value)
                        spider.logger.info(f"üîã –ë–∞—Ç–∞—Ä–µ—è: '{original_value}' ‚Üí '{mah_value} –º–ê¬∑–≥'")
                    except (ValueError, AttributeError) as e:
                        spider.logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –±–∞—Ç–∞—Ä–µ—è: {e}")
        
        return specs_list
    
    def _extract_dimensions_from_specs(self, specs_list, spider):
        """
        –í–∏—Ç—è–≥—É—î –≥–∞–±–∞—Ä–∏—Ç–∏ –∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¥–ª—è –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫ PROM.
        –ö–æ–Ω–≤–µ—Ä—Ç—É—î –º–º ‚Üí —Å–º, –≥ ‚Üí –∫–≥
        
        –®—É–∫–∞—î:
        - –í–∞–≥–∞ (–≤–∂–µ –≤ –≥ –ø—ñ—Å–ª—è –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—É) ‚Üí –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –≤ –∫–≥
        - –®–∏—Ä–∏–Ω–∞ (–º–º) ‚Üí —Å–º
        - –í–∏—Å–æ—Ç–∞ (–º–º) ‚Üí —Å–º
        - –î–æ–≤–∂–∏–Ω–∞ (–º–º) ‚Üí —Å–º
        """
        dimensions = {
            "–í–∞–≥–∞,–∫–≥": "",
            "–®–∏—Ä–∏–Ω–∞,—Å–º": "",
            "–í–∏—Å–æ—Ç–∞,—Å–º": "",
            "–î–æ–≤–∂–∏–Ω–∞,—Å–º": ""
        }
        
        if not specs_list:
            return dimensions
        
        # –ú–∞–ø—ñ–Ω–≥ –Ω–∞–∑–≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ ‚Üí –∫–æ–ª–æ–Ω–∫–∏ PROM
        weight_keys = ['–≤–∞–≥–∞', '–≤–∞–≥–∞ –±—Ä—É—Ç—Ç–æ', '–≤–∞–≥–∞ –Ω–µ—Ç—Ç–æ', 'weight', 'gross weight', 'net weight']
        width_keys = ['—à–∏—Ä–∏–Ω–∞', 'width']
        height_keys = ['–≤–∏—Å–æ—Ç–∞', '–≤—ã—Å–æ—Ç–∞', 'height']
        length_keys = ['–¥–æ–≤–∂–∏–Ω–∞', '–¥–ª–∏–Ω–∞', 'length', '–≥–ª–∏–±–∏–Ω–∞', '–≥–ª—É–±–∏–Ω–∞', 'depth']
        
        for spec in specs_list:
            spec_name = spec.get('name', '').lower().strip()
            spec_value = spec.get('value', '').strip()
            spec_unit = spec.get('unit', '').lower().strip()
            
            if not spec_value:
                continue
            
            # 1. –í–ê–ì–ê: –∑ –≥ ‚Üí –∫–≥ (–ø—ñ—Å–ª—è –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—É –≤–∂–µ –≤ –≥—Ä–∞–º–∞—Ö)
            if spec_name in weight_keys:
                match_g = re.search(r'([0-9\.]+)', spec_value)
                if match_g:
                    try:
                        grams = float(match_g.group(1))
                        kg = grams / 1000
                        dimensions["–í–∞–≥–∞,–∫–≥"] = f"{kg:.3f}".replace('.', ',')
                        spider.logger.debug(f"‚öñÔ∏è –í–∞–≥–∞: {grams}–≥ ‚Üí {kg}–∫–≥")
                    except ValueError:
                        pass
            
            # 2. –®–ò–†–ò–ù–ê: –∑ –º–º ‚Üí —Å–º (–ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ unit –∞–±–æ value)
            elif spec_name in width_keys:
                if spec_unit == '–º–º' or '–º–º' in spec_value:
                    match_num = re.search(r'([0-9\.]+)', spec_value)
                    if match_num:
                        try:
                            mm = float(match_num.group(1))
                            cm = mm / 10
                            dimensions["–®–∏—Ä–∏–Ω–∞,—Å–º"] = f"{cm:.1f}".replace('.', ',')
                            spider.logger.debug(f"üìè –®–∏—Ä–∏–Ω–∞: {mm}–º–º ‚Üí {cm}—Å–º")
                        except ValueError:
                            pass
            
            # 3. –í–ò–°–û–¢–ê: –∑ –º–º ‚Üí —Å–º (–ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ unit –∞–±–æ value)
            elif spec_name in height_keys:
                if spec_unit == '–º–º' or '–º–º' in spec_value:
                    match_num = re.search(r'([0-9\.]+)', spec_value)
                    if match_num:
                        try:
                            mm = float(match_num.group(1))
                            cm = mm / 10
                            dimensions["–í–∏—Å–æ—Ç–∞,—Å–º"] = f"{cm:.1f}".replace('.', ',')
                            spider.logger.debug(f"üìè –í–∏—Å–æ—Ç–∞: {mm}–º–º ‚Üí {cm}—Å–º")
                        except ValueError:
                            pass
            
            # 4. –î–û–í–ñ–ò–ù–ê: –∑ –º–º ‚Üí —Å–º (–ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ unit –∞–±–æ value)
            elif spec_name in length_keys:
                if spec_unit == '–º–º' or '–º–º' in spec_value:
                    match_num = re.search(r'([0-9\.]+)', spec_value)
                    if match_num:
                        try:
                            mm = float(match_num.group(1))
                            cm = mm / 10
                            dimensions["–î–æ–≤–∂–∏–Ω–∞,—Å–º"] = f"{cm:.1f}".replace('.', ',')
                            spider.logger.debug(f"üìè –î–æ–≤–∂–∏–Ω–∞: {mm}–º–º ‚Üí {cm}—Å–º")
                        except ValueError:
                            pass
        
        return dimensions
    
    def _increment_stat(self, output_file, stat_key):
        """–Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if output_file not in self.stats:
            self.stats[output_file] = {
                "count": 0,
                "filtered_no_price": 0,
                "filtered_no_stock": 0,
            }
        self.stats[output_file][stat_key] += 1

    def _load_initial_product_code(self, spider_name, logger):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–æ—á–∞—Ç–∫–æ–≤–æ–≥–æ –∫–æ–¥—É —Ç–æ–≤–∞—Ä—É"""
        supplier_prefix = spider_name.split('_')[0]
        counter_file_path = Path(r"C:\FullStack\Scrapy\data") / supplier_prefix / f"{supplier_prefix}_counter_product_code.csv"
        
        try:
            with open(counter_file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                for row in reader:
                    if row:
                        match = re.search(r'(\d+)', row[0])
                        if match:
                            initial_code = int(match.group(1))
                            logger.info(f"‚úÖ –ü–æ—á–∞—Ç–∫–æ–≤–∏–π –∫–æ–¥: {initial_code}")
                            return initial_code
            return 200000
        except FileNotFoundError:
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –ª—ñ—á–∏–ª—å–Ω–∏–∫–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {counter_file_path}")
            return 200000
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–¥—É: {e}")
            return 200000


class ValidationPipeline:
    """–î–æ–¥–∞—Ç–∫–æ–≤–∏–π pipeline –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó"""
    
    def process_item(self, item, spider):
        adapter = ItemAdapter(item)
        
        if not adapter.get("–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó"):
            raise DropItem("–í—ñ–¥—Å—É—Ç–Ω—è –Ω–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É")
        
        if not adapter.get("–¶—ñ–Ω–∞"):
            raise DropItem("–í—ñ–¥—Å—É—Ç–Ω—è —Ü—ñ–Ω–∞")
        
        try:
            float(str(adapter.get("–¶—ñ–Ω–∞")).replace(",", "."))
        except (ValueError, TypeError):
            raise DropItem(f"–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ —Ü—ñ–Ω–∞: {adapter.get('–¶—ñ–Ω–∞')}")
        
        return item
