"""
–ë–∞–∑–æ–≤—ñ –∫–ª–∞—Å–∏ –¥–ª—è –≤—Å—ñ—Ö –ø–∞—É–∫—ñ–≤-–ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤.
–ú—ñ–Ω—ñ–º—ñ–∑—É—î –¥—É–±–ª—é–≤–∞–Ω–Ω—è –∫–æ–¥—É —Ç–∞ –∑–∞–±–µ–∑–ø–µ—á—É—î —É–Ω—ñ—Ñ—ñ–∫–æ–≤–∞–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥.
"""
import scrapy
import re
from pathlib import Path
from typing import Optional, Dict, List


class BaseSupplierSpider(scrapy.Spider):
    """–ë–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –≤—Å—ñ—Ö –ø–∞—É–∫—ñ–≤ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤"""
    
    # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º (–º–æ–∂–Ω–∞ –ø–µ—Ä–µ–≤–∏–∑–Ω–∞—á–∏—Ç–∏ –≤ –¥–æ—á—ñ—Ä–Ω—ñ—Ö –∫–ª–∞—Å–∞—Ö)
    custom_settings = {
        "CONCURRENT_REQUESTS": 8,
        "CONCURRENT_REQUESTS_PER_DOMAIN": 8,
        "AUTOTHROTTLE_ENABLED": True,
        "AUTOTHROTTLE_START_DELAY": 1,
        "AUTOTHROTTLE_MAX_DELAY": 60,
        "AUTOTHROTTLE_TARGET_CONCURRENCY": 2.0,
    }
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.processed_products = set()
        self.failed_products = []
    
    def _clean_price(self, price_str: str) -> str:
        """–û—á–∏—â–µ–Ω–Ω—è —Ü—ñ–Ω–∏ –≤—ñ–¥ –∑–∞–π–≤–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤"""
        if not price_str:
            return ""
        
        price_str = price_str.replace(" ", "").replace("–≥—Ä–Ω", "").replace("‚Ç¥", "")
        price_str = price_str.replace("—É.–µ.", "").replace("$", "").replace("USD", "")
        price_str = price_str.replace(",", ".")
        
        try:
            cleaned = "".join(c for c in price_str if c.isdigit() or c == ".")
            return str(float(cleaned)) if cleaned else ""
        except ValueError:
            return ""
    
    def _normalize_availability(self, availability: Optional[str]) -> str:
        """–ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Å—Ç–∞—Ç—É—Å—É –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ"""
        if not availability:
            return "–£—Ç–æ—á–Ω—è–π—Ç–µ"
        
        availability_lower = availability.lower()
        
        if any(word in availability_lower for word in ["—î –≤ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ", "–≤ –Ω–∞–ª–∏—á–∏–∏", "–µ—Å—Ç—å", "–∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è", "–∑–∞–∫—ñ–Ω—á—É—î—Ç—å—Å—è"]):
            return "–í –Ω–∞–ª–∏—á–∏–∏"
        elif any(word in availability_lower for word in ["–ø—ñ–¥ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è", "–ø–æ–¥ –∑–∞–∫–∞–∑"]):
            return "–ü–æ–¥ –∑–∞–∫–∞–∑"
        elif any(word in availability_lower for word in ["–Ω–µ–º–∞—î", "–Ω–µ—Ç"]):
            return "–ù–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏"
        else:
            return "–£—Ç–æ—á–Ω—è–π—Ç–µ"
    
    def _extract_quantity(self, text: Optional[str]) -> str:
        """–í–∏—Ç—è–≥—É—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑ —Ç–µ–∫—Å—Ç—É –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ"""
        if not text:
            return ""
        
        quantity_match = re.search(r'\d+', text)
        if quantity_match:
            return quantity_match.group(0)
        
        return ""
    
    def _sanitize_image_url(self, url: str) -> str:
        """–ï–∫—Ä–∞–Ω—É—î —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ —Å–∏–º–≤–æ–ª–∏ –≤ URL –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è PROM
        
        PROM –Ω–µ –ø—Ä–∏–π–º–∞—î URL —ñ–∑ –∑–∞–ø—è—Ç–∏–º–∏ - –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–∞–º—ñ–Ω–∏—Ç–∏ –Ω–∞ %2C
        """
        if not url:
            return ""
        
        # –ó–∞–º—ñ–Ω—é—î–º–æ –∑–∞–ø—è—Ç—É—é –Ω–∞ %2C
        url = url.replace(",", "%2C")
        
        return url
    
    def _load_keywords_mapping(self) -> Dict[str, Dict[str, List[str]]]:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –º–∞–ø–ø—ñ–Ω–≥ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ –∑ CSV –∑–∞ –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_–ø—ñ–¥—Ä–æ–∑–¥—ñ–ª—É
        
        –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
        {
            "301105": {
                "keywords_ru": [...],  # –ö–∞—Ç–µ–≥–æ—Ä—ñ–π–Ω—ñ –∫–ª—é—á—ñ
                "keywords_ua": [...],
                "characteristics_ru": [...],  # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏—á–Ω—ñ –∫–ª—é—á—ñ
                "characteristics_ua": [...]
            }
        }
        """
        import csv
        mapping = {}
        csv_path = Path(r"C:\FullStack\Scrapy\data\viatec\viatec_keywords.csv")
        if not csv_path.exists():
            self.logger.warning("viatec_keywords.csv not found")
            return mapping
        try:
            with open(csv_path, encoding="utf-8-sig") as f:
                reader = csv.DictReader(f, delimiter=";")
                for row in reader:
                    subdivision_id = row["–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_–ø—ñ–¥—Ä–æ–∑–¥—ñ–ª—É"].strip()
                    mapping[subdivision_id] = {
                        "keywords_ru": [w.strip() for w in row["keywords_ru"].strip('"').split(",") if w.strip()],
                        "keywords_ua": [w.strip() for w in row["keywords_ua"].strip('"').split(",") if w.strip()],
                        "characteristics_ru": [w.strip() for w in row["characteristics_ru"].strip('"').split(",") if w.strip()],
                        "characteristics_ua": [w.strip() for w in row["characteristics_ua"].strip('"').split(",") if w.strip()],
                    }
            self.logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(mapping)} –ø—ñ–¥—Ä–æ–∑–¥—ñ–ª—ñ–≤ –∑ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è viatec_keywords.csv: {e}")
        return mapping
    
    def _extract_model_components(self, title: str, lang: str = "ua") -> List[str]:
        """–í–∏—Ç—è–≥—É—î –∫–ª—é—á–æ–≤—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –∑ –Ω–∞–∑–≤–∏ —Ç–æ–≤–∞—Ä—É (–ë–õ–û–ö 1)
        
        –ü—Ä–∏–∫–ª–∞–¥ –≤—Ö–æ–¥—É: "Turbo HD –≤—ñ–¥–µ–æ–∫–∞–º–µ—Ä–∞ Hikvision DS-2CE16H0T-ITF(–°) 5–ú–ü (2.8–º–º)"
        –†–µ–∑—É–ª—å—Ç–∞—Ç:
        - DS-2CE16H0T-ITF
        - Hikvision DS-2CE16H0T-ITF
        - Turbo HD Hikvision
        - 5MP Hikvision
        - Hikvision 2.8mm
        """
        if not title:
            return []
        
        components = []
        title_lower = title.lower()
        
        # 1. –í–∏—Ç—è–≥—É—î–º–æ –±—Ä–µ–Ω–¥–∏
        brands = ["hikvision", "dahua", "ezviz", "imou", "uniview", "axis", "tp-link", "mikrotik", 
                  "ajax", "ubiquiti", "wd", "western digital", "seagate", "pulsar", "infiray", "dji"]
        
        detected_brand = None
        for brand in brands:
            if brand in title_lower:
                # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –±—Ä–µ–Ω–¥ –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º —Ä–µ–≥—ñ—Å—Ç—Ä–æ–º
                brand_idx = title_lower.find(brand)
                detected_brand = title[brand_idx:brand_idx+len(brand)]
                break
        
        # 2. –í–∏—Ç—è–≥—É—î–º–æ –∫–æ–¥ –º–æ–¥–µ–ª—ñ (–∑–∞–∑–≤–∏—á–∞–π –∑ –¥–µ—Ñ—ñ—Å–∞–º–∏ —Ç–∞ —Ü–∏—Ñ—Ä–∞–º–∏)
        model_pattern = re.compile(r'[A-Z]{2,}-[A-Z0-9-]+[A-Z0-9](?:\([A-Z–∞-—è–ê-–Ø]\))?', re.IGNORECASE)
        model_matches = model_pattern.findall(title)
        
        model_code = None
        if model_matches:
            # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à–µ –∑–Ω–∞–π–¥–µ–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è
            model_code = model_matches[0]
            components.append(model_code)
        
        # 3. –ë—Ä–µ–Ω–¥ + –º–æ–¥–µ–ª—å
        if detected_brand and model_code:
            components.append(f"{detected_brand} {model_code}")
        
        # 4. –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—é (Turbo HD, IP, AHD, TVI, —Ç–æ—â–æ)
        technologies = ["turbo hd", "ip", "ahd", "tvi", "cvi", "analog", "nvr", "dvr", "hybrid"]
        for tech in technologies:
            if tech in title_lower and detected_brand:
                tech_idx = title_lower.find(tech)
                tech_original = title[tech_idx:tech_idx+len(tech)]
                components.append(f"{tech_original} {detected_brand}")
                break
        
        # 5. –†–æ–∑–¥—ñ–ª—å–Ω—ñ—Å—Ç—å (2MP, 4MP, 5MP, 8MP, —Ç–æ—â–æ)
        resolution_pattern = re.compile(r'\d+\s*[Mm][Pp]|–¥+\s*–ú–ü', re.IGNORECASE)
        resolution_match = resolution_pattern.search(title)
        if resolution_match and detected_brand:
            resolution = resolution_match.group(0)
            components.append(f"{resolution} {detected_brand}")
        
        # 6. –§–æ–∫—É—Å–Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å (2.8mm, 3.6mm, —Ç–æ—â–æ)
        focal_pattern = re.compile(r'\d+\.\d+\s*–º–º', re.IGNORECASE)
        focal_match = focal_pattern.search(title)
        if focal_match and detected_brand:
            focal = focal_match.group(0)
            components.append(f"{detected_brand} {focal}")
        
        # 7. –ö–∞–Ω–∞–ª–∏ (–¥–ª—è —Ä–µ—î—Å—Ç—Ä–∞—Ç–æ—Ä—ñ–≤: 4, 8, 16, 32 –∫–∞–Ω–∞–ª—ñ–≤/–∫–∞–Ω–∞–ª–æ–≤)
        if lang == "ua" and "–∫–∞–Ω–∞–ª" in title_lower:
            channels_pattern = re.compile(r'(\d+)\s*–∫–∞–Ω–∞–ª', re.IGNORECASE)
            channels_match = channels_pattern.search(title)
            if channels_match:
                components.append(f"—Ä–µ—î—Å—Ç—Ä–∞—Ç–æ—Ä {channels_match.group(1)} –∫–∞–Ω–∞–ª—ñ–≤")
        elif lang == "ru" and "–∫–∞–Ω–∞–ª" in title_lower:
            channels_pattern = re.compile(r'(\d+)\s*–∫–∞–Ω–∞–ª', re.IGNORECASE)
            channels_match = channels_pattern.search(title)
            if channels_match:
                components.append(f"—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç–æ—Ä {channels_match.group(1)} –∫–∞–Ω–∞–ª–æ–≤")
        
        # 8. –Ñ–º–Ω—ñ—Å—Ç—å (1TB, 2TB, —Ç–æ—â–æ - –¥–ª—è HDD)
        capacity_pattern = re.compile(r'\d+\s*[Tt–ì–≥][Bb–ë–±]', re.IGNORECASE)
        capacity_match = capacity_pattern.search(title)
        if capacity_match:
            capacity = capacity_match.group(0).upper()
            components.append(f"HDD {capacity}")
        
        # –í–∏–¥–∞–ª—è—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏
        seen = set()
        unique_components = []
        for comp in components:
            comp_lower = comp.lower()
            if comp_lower not in seen:
                unique_components.append(comp)
                seen.add(comp_lower)
        
        return unique_components[:8]  # –û–±–º–µ–∂—É—î–º–æ –¥–æ 8 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
    
    def _generate_search_terms(self, product_name: str, subdivision_id: str = "", lang: str = "ua") -> str:
        """–ì–µ–Ω–µ—Ä—É—î –ø–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏ –∑–∞ –ª–æ–≥—ñ–∫–æ—é:
        
        –ë–õ–û–ö 1: –ú–æ–¥–µ–ª—å–Ω—ñ –∫–ª—é—á—ñ (5-8 —à—Ç.) - –∑ –Ω–∞–∑–≤–∏ —Ç–æ–≤–∞—Ä—É
        –ë–õ–û–ö 2: –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏—á–Ω—ñ –∫–ª—é—á—ñ - –∑ characteristics, —è–∫–∏—Ö –ù–ï–ú–ê–Ñ –≤ –Ω–∞–∑–≤—ñ (–¥–æ 18 —Ä–∞–∑–æ–º –∑ –ë–õ–û–ö 1)
        –ë–õ–û–ö 3: –ö–∞—Ç–µ–≥–æ—Ä—ñ–π–Ω—ñ –∫–ª—é—á—ñ - –≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ –∑ keywords
        
        –ú—ñ–Ω—ñ–º—É–º: 8 –∫–ª—é—á—ñ–≤ (–∑ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è–º —è–∫—â–æ –º–µ–Ω—à–µ)
        –ú–∞–∫—Å–∏–º—É–º: –±–µ–∑ –æ–±–º–µ–∂–µ–Ω—å
        """
        if not product_name:
            return ""
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∫–ª—é—á—ñ –∑–∞ –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä_–ø—ñ–¥—Ä–æ–∑–¥—ñ–ª—É –æ–¥–∏–Ω —Ä–∞–∑
        if not hasattr(self, "_keywords_cache"):
            self._keywords_cache = self._load_keywords_mapping()
        
        result = []
        seen = set()
        product_name_lower = product_name.lower()
        
        # –ë–õ–û–ö 1: –ú–æ–¥–µ–ª—å–Ω—ñ –∫–ª—é—á—ñ (5-8 —à—Ç.) - –≤–∏—Ç—è–≥—É—î–º–æ –∑ –Ω–∞–∑–≤–∏
        model_components = self._extract_model_components(product_name, lang)
        for comp in model_components:
            comp_lower = comp.lower()
            if comp_lower not in seen:
                result.append(comp)
                seen.add(comp_lower)
        
        # –ë–õ–û–ö 2: –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏—á–Ω—ñ –∫–ª—é—á—ñ (6-10 —à—Ç.) - –∑ CSV, —è–∫–∏—Ö –ù–ï–ú–ê–Ñ –≤ –Ω–∞–∑–≤—ñ
        if subdivision_id and subdivision_id in self._keywords_cache:
            lang_key = f"characteristics_{lang}" if lang in ["ua", "ru"] else "characteristics_ua"
            characteristics = self._keywords_cache[subdivision_id].get(lang_key, [])
            
            for char in characteristics:
                char_lower = char.lower()
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ 1: –ß–∏ –Ω–µ —î —Ü—è —Ñ—Ä–∞–∑–∞ –ø–æ–≤–Ω—ñ—Å—Ç—é –ø—ñ–¥—Ñ—Ä–∞–∑–æ—é –Ω–∞–∑–≤–∏?
                if char_lower in product_name_lower:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ, –±–æ —Ç–æ—á–Ω–æ —î –≤ –Ω–∞–∑–≤—ñ
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ 2: –ß–∏ –Ω–µ —Å–ø—ñ–≤–ø–∞–¥–∞—é—Ç—å –≤—Å—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞?
                char_words = [w for w in char_lower.split() if len(w) > 2]
                if not char_words:  # –Ø–∫—â–æ –Ω–µ–º–∞—î –∑–Ω–∞—á—É—â–∏—Ö —Å–ª—ñ–≤
                    continue
                
                # –†–∞—Ö—É—î–º–æ —Å–∫—ñ–ª—å–∫–∏ —Å–ª—ñ–≤ —î –≤ –Ω–∞–∑–≤—ñ
                words_in_title = sum(1 for word in char_words if word in product_name_lower)
                
                # –Ø–∫—â–æ –±—ñ–ª—å—à–µ 70% —Å–ª—ñ–≤ —î –≤ –Ω–∞–∑–≤—ñ - –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ
                if len(char_words) > 0 and words_in_title / len(char_words) > 0.7:
                    continue
                
                # –î–æ–¥–∞—î–º–æ —è–∫—â–æ —â–µ –Ω–µ –±—É–ª–æ
                if char_lower not in seen:
                    result.append(char)
                    seen.add(char_lower)
                    if len(result) >= 18:  # –û–±–º–µ–∂—É—î–º–æ –ë–õ–û–ö 1 + –ë–õ–û–ö 2 –¥–æ 18 –∫–ª—é—á—ñ–≤
                        break
        
        # –ë–õ–û–ö 3: –ö–∞—Ç–µ–≥–æ—Ä—ñ–π–Ω—ñ –∫–ª—é—á—ñ (–≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ) - –∑–∞–≤–∂–¥–∏ –¥–æ–¥–∞—î–º–æ
        if subdivision_id and subdivision_id in self._keywords_cache:
            lang_key = f"keywords_{lang}" if lang in ["ua", "ru"] else "keywords_ua"
            category_keywords = self._keywords_cache[subdivision_id].get(lang_key, [])
            
            for kw in category_keywords:  # –î–æ–¥–∞—î–º–æ –≤—Å—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π–Ω—ñ –∫–ª—é—á—ñ
                kw_lower = kw.lower()
                if kw_lower not in seen:
                    result.append(kw)
                    seen.add(kw_lower)
        
        # –ì–∞—Ä–∞–Ω—Ç—É—î–º–æ –º—ñ–Ω—ñ–º—É–º 8 –∫–ª—é—á—ñ–≤
        if len(result) < 8:
            # –Ø–∫—â–æ –º–µ–Ω—à–µ 8 –∫–ª—é—á—ñ–≤, –ª–æ–≥—É—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è
            self.logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ –¥–ª—è —Ç–æ–≤–∞—Ä—É. –ó–Ω–∞–π–¥–µ–Ω–æ: {len(result)} (–º—ñ–Ω—ñ–º—É–º: 8)")
        
        return ", ".join(result)


class BaseRetailSpider(BaseSupplierSpider):
    """–ë–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è —Ä–æ–∑–¥—Ä—ñ–±–Ω–∏—Ö –ø–∞—É–∫—ñ–≤"""
    
    price_type = "retail"
    currency = "UAH"
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∏—Ö –¥–ª—è —Ä–æ–∑–¥—Ä—ñ–±—É –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç–µ–π
        if not hasattr(self, 'supplier_id'):
            raise ValueError(f"Spider {self.name} must define 'supplier_id' attribute")
        
        if not hasattr(self, 'output_filename'):
            self.output_filename = f"{self.supplier_id}_retail.csv"


class BaseDealerSpider(BaseSupplierSpider):
    """–ë–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –¥–∏–ª–µ—Ä—Å—å–∫–∏—Ö –ø–∞—É–∫—ñ–≤"""
    
    price_type = "dealer"
    currency = "USD"
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∏—Ö –¥–ª—è –¥–∏–ª–µ—Ä—ñ–≤ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç–µ–π
        if not hasattr(self, 'supplier_id'):
            raise ValueError(f"Spider {self.name} must define 'supplier_id' attribute")
        
        if not hasattr(self, 'output_filename'):
            self.output_filename = f"{self.supplier_id}_dealer.csv"


class EserverBaseSpider(BaseSupplierSpider):
    """–ë–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –ø–∞—É–∫—ñ–≤ E-Server (–∑–∞–≥–∞–ª—å–Ω–∞ –ª–æ–≥—ñ–∫–∞ –¥–ª—è retail —ñ dealer)"""
    
    allowed_domains = ["e-server.com.ua"]
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.category_urls = []
        self.products_from_pagination = []
    
    def _extract_manufacturer(self, product_name: str) -> str:
        """–í–∏–∑–Ω–∞—á–∞—î –≤–∏—Ä–æ–±–Ω–∏–∫–∞ –∑ –Ω–∞–∑–≤–∏ —Ç–æ–≤–∞—Ä—É"""
        if not product_name:
            return ""
        
        product_name_lower = product_name.lower()
        
        # –ü–†–Ü–û–†–ò–¢–ï–¢ 1: –Ø–≤–Ω—ñ –∑–≥–∞–¥–∫–∏ –±—Ä–µ–Ω–¥—ñ–≤
        priority_patterns = {
            "eserver": "EServer",
            "e-server": "EServer",
            "hikvision": "Hikvision",
            "dahua": "Dahua Technology",
            "axis": "Axis",
            "uniview": "UniView",
            "imou": "Imou",
            "ezviz": "Ezviz",
            "unv": "UNV",
            "hiwatch": "HiWatch",
            "ajax": "Ajax",
            "tp-link": "TP-Link",
            "mikrotik": "MikroTik",
            "ubiquiti": "Ubiquiti",
        }
        
        for pattern, name in priority_patterns.items():
            if pattern in product_name_lower:
                return name
        
        return ""
    
    def closed(self, reason):
        """–í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ñ –ø–∞—É–∫–∞"""
        self.logger.info(f"üéâ –ü–∞—É–∫ {self.name} –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ü—Ä–∏—á–∏–Ω–∞: {reason}")
        
        if self.failed_products:
            self.logger.info("=" * 80)
            self.logger.info("üì¶ –°–ü–ò–°–û–ö –¢–û–í–ê–†–Ü–í –ó –ü–û–ú–ò–õ–ö–ê–ú–ò –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø")
            self.logger.info("=" * 80)
            for failed in self.failed_products:
                self.logger.error(f"- –¢–æ–≤–∞—Ä: {failed['product_name']} | URL: {failed['url']} | –ü—Ä–∏—á–∏–Ω–∞: {failed['reason']}")
            self.logger.info("=" * 80)
        else:
            self.logger.info("‚úÖ –¢–æ–≤–∞—Ä—ñ–≤ –∑ –ø–æ–º–∏–ª–∫–∞–º–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        
        # –ó–≤—É–∫–æ–≤–∏–π —Å–∏–≥–Ω–∞–ª (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ, –ø—Ä–∞—Ü—é—î —Ç—ñ–ª—å–∫–∏ –Ω–∞ Windows)
        try:
            import winsound
            for _ in range(3):
                winsound.Beep(1000, 300)
            self.logger.info("üîî –ó–≤—É–∫–æ–≤–∏–π —Å–∏–≥–Ω–∞–ª –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–æ!")
        except Exception as e:
            self.logger.debug(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥—Ç–≤–æ—Ä–∏—Ç–∏ –∑–≤—É–∫: {e}")


class ViatecBaseSpider(BaseSupplierSpider):
    """–ë–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –ø–∞—É–∫—ñ–≤ Viatec (–∑–∞–≥–∞–ª—å–Ω–∞ –ª–æ–≥—ñ–∫–∞ –¥–ª—è retail —ñ dealer)"""
    
    allowed_domains = ["viatec.ua"]
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.category_urls = []
        self.products_from_pagination = []
    
    def _extract_manufacturer(self, product_name: str) -> str:
        """–í–∏–∑–Ω–∞—á–∞—î –≤–∏—Ä–æ–±–Ω–∏–∫–∞ –∑ –Ω–∞–∑–≤–∏ —Ç–æ–≤–∞—Ä—É"""
        if not product_name:
            return ""
        
        product_name_lower = product_name.lower()
        
        # –ü–†–Ü–û–†–ò–¢–ï–¢ 1: –Ø–≤–Ω—ñ –∑–≥–∞–¥–∫–∏ –±—Ä–µ–Ω–¥—ñ–≤
        priority_patterns = {
            "hikvision": "Hikvision",
            "dahua": "Dahua Technology",
            "axis": "Axis",
            "uniview": "UniView",
            "imou": "Imou",
            "ezviz": "Ezviz",
            "unv": "UNV",
            "hiwatch": "HiWatch",
            "ajax": "Ajax",
            "tp-link": "TP-Link",
            "mikrotik": "MikroTik",
            "ubiquiti": "Ubiquiti",
        }
        
        for pattern, name in priority_patterns.items():
            if pattern in product_name_lower:
                return name
        
        # –ü–†–Ü–û–†–ò–¢–ï–¢ 2: –ö–æ–¥–∏ –ø—Ä–æ–¥—É–∫—Ç—ñ–≤ –∑ –¥–µ—Ñ—ñ—Å–æ–º
        code_patterns = {
            "ds-": "Hikvision",
            "dh-": "Dahua Technology",
            "dhi-": "Dahua Technology",
            "vto-": "Dahua Technology",
            "vtm-": "Dahua Technology",
        }
        
        for pattern, name in code_patterns.items():
            if pattern in product_name_lower:
                return name
        
        # –ü–†–Ü–û–†–ò–¢–ï–¢ 3: –ú–∞–ø–ø—ñ–Ω–≥ –∑ CSV
        if not hasattr(self, "_manufacturers_cache"):
            self._manufacturers_cache = self._load_manufacturers_from_csv()
        
        sorted_manufacturers = sorted(
            self._manufacturers_cache.items(),
            key=lambda x: len(x[0]),
            reverse=True
        )
        
        for keyword, manufacturer in sorted_manufacturers:
            keyword_lower = keyword.lower()
            if len(keyword) <= 2:
                pattern = r'\b' + re.escape(keyword_lower) + r'\b'
                if re.search(pattern, product_name_lower):
                    return manufacturer
            else:
                if keyword_lower in product_name_lower:
                    return manufacturer
        
        return ""
    
    def _load_manufacturers_from_csv(self) -> Dict[str, str]:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –º–∞–ø–ø—ñ–Ω–≥ –≤–∏—Ä–æ–±–Ω–∏–∫—ñ–≤ –∑ CSV"""
        import csv
        mapping = {}
        try:
            csv_path = Path(r"C:\FullStack\Scrapy\data\viatec\viatec_manufacturers.csv")
            if csv_path.exists():
                with open(csv_path, encoding="utf-8-sig") as f:
                    reader = csv.DictReader(f, delimiter=";")
                    for row in reader:
                        keyword = row.get("–°–ª–æ–≤–æ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–∞", "").strip()
                        manufacturer = row.get("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å (–≤–∏—Ä–æ–±–Ω–∏–∫)", "").strip()
                        if keyword and manufacturer:
                            mapping[keyword] = manufacturer
                self.logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(mapping)} –≤–∏—Ä–æ–±–Ω–∏–∫—ñ–≤ –∑ CSV")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–∏—Ä–æ–±–Ω–∏–∫—ñ–≤: {e}")
        
        return mapping
    
    def _extract_description_with_br(self, response) -> str:
        """
        –í–∏—Ç—è–≥—É—î –æ–ø–∏—Å –∑—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º –ø–µ—Ä–µ–Ω–æ—Å—ñ–≤ <br> —Ç–∞ –æ–±—Ä–æ–±–∫–æ—é —Å–ø–∏—Å–∫—ñ–≤ <ul>
        """
        description_container = response.css("div.card-header__card-info-text")
        if not description_container:
            self.logger.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –æ–ø–∏—Å—É –Ω–∞ {response.url}")
            return ""
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å <ul>
        ul_list = description_container.css("ul")
        if ul_list:
            self.logger.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ <ul> —Å–ø–∏—Å–æ–∫ –≤ –æ–ø–∏—Å—ñ –Ω–∞ {response.url}")
            list_items = ul_list.css("li")
            
            description_parts = []
            for item in list_items:
                inner_content = item.get()
                inner_content = re.sub(r'</?li[^>]*>', '', inner_content).strip()
                if not inner_content.startswith('‚óè'):
                    description_parts.append(f"‚óè {inner_content}")
                else:
                    description_parts.append(inner_content)
            
            return "<br>".join(description_parts)
        
        # –û–±—Ä–æ–±–∫–∞ <p> —Ç–µ–≥—ñ–≤
        p_tags = description_container.css("p")
        if p_tags:
            self.logger.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ <p> —Ç–µ–≥–∏ –≤ –æ–ø–∏—Å—ñ –Ω–∞ {response.url}")
            result_parts = []
            for p in p_tags:
                if p.css("::attr(class)").get() == "card-header__analog-link":
                    continue
                
                p_html = p.get()
                inner_html = re.sub(r'^<p[^>]*>|</p>$', '', p_html).strip()
                
                if inner_html:
                    inner_html = inner_html.replace("<br/>", "<br>").replace("<br />", "<br>")
                    result_parts.append(inner_html)
            
            return "<br>".join(result_parts)
        
        self.logger.warning(f"–í –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ñ –æ–ø–∏—Å—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –Ω—ñ <ul>, –Ω—ñ <p> –Ω–∞ {response.url}")
        return ""
    
    def _extract_specifications(self, response) -> List[Dict[str, str]]:
        """
        –í–∏—Ç—è–≥—É—î —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–æ–≤–∞—Ä—É –∑ —Ç–∞–±–ª–∏—Ü—ñ (—É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –Ω–∞–∑–≤–∏)
        """
        specs_list = []
        
        # –°–ø—Ä–æ–±–∞ 1: –ê–∫—Ç–∏–≤–Ω–∞ –≤–∫–ª–∞–¥–∫–∞
        spec_rows = response.css("li.card-tabs__item.active div.card-tabs__characteristic-content table tr")
        
        # –°–ø—Ä–æ–±–∞ 2: –ë—É–¥—å-—è–∫–∞ –≤–∫–ª–∞–¥–∫–∞ –∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
        if not spec_rows:
            spec_rows = response.css("div.card-tabs__characteristic-content table tr")
        
        # –°–ø—Ä–æ–±–∞ 3: –ó–∞–≥–∞–ª—å–Ω–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä —Ç–∞–±–ª–∏—Ü—ñ
        if not spec_rows:
            spec_rows = response.css("ul.card-tabs__list table tr")
        
        for row in spec_rows[:60]:
            name = row.css("th::text").get()
            value = row.css("td::text").get()
            
            if name and value:
                specs_list.append({
                    "name": name.strip(),
                    "value": value.strip(),
                    "unit": ""
                })
        
        return specs_list
    
    def _convert_to_ru_url(self, url: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç—É—î —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏–π URL –≤ —Ä–æ—Å—ñ–π—Å—å–∫–∏–π"""
        if "/ru/" not in url:
            url = url.replace("viatec.ua/", "viatec.ua/ru/")
        return url
    
    def closed(self, reason):
        """–í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ñ –ø–∞—É–∫–∞"""
        self.logger.info(f"üéâ –ü–∞—É–∫ {self.name} –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ü—Ä–∏—á–∏–Ω–∞: {reason}")
        
        if self.failed_products:
            self.logger.info("=" * 80)
            self.logger.info("üì¶ –°–ü–ò–°–û–ö –¢–û–í–ê–†–Ü–í –ó –ü–û–ú–ò–õ–ö–ê–ú–ò –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø")
            self.logger.info("=" * 80)
            for failed in self.failed_products:
                self.logger.error(f"- –¢–æ–≤–∞—Ä: {failed['product_name']} | URL: {failed['url']} | –ü—Ä–∏—á–∏–Ω–∞: {failed['reason']}")
            self.logger.info("=" * 80)
        else:
            self.logger.info("‚úÖ –¢–æ–≤–∞—Ä—ñ–≤ –∑ –ø–æ–º–∏–ª–∫–∞–º–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        
        # –ó–≤—É–∫–æ–≤–∏–π —Å–∏–≥–Ω–∞–ª (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ, –ø—Ä–∞—Ü—é—î —Ç—ñ–ª—å–∫–∏ –Ω–∞ Windows)
        try:
            import winsound
            for _ in range(3):
                winsound.Beep(1000, 300)
            self.logger.info("üîî –ó–≤—É–∫–æ–≤–∏–π —Å–∏–≥–Ω–∞–ª –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–æ!")
        except Exception as e:
            self.logger.debug(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥—Ç–≤–æ—Ä–∏—Ç–∏ –∑–≤—É–∫: {e}")
